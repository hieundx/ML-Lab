{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "This code is written after Andrew Ng's ML Specialization for my own study purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w (443, 10): 443 users with 10 features\n",
    "w_data = pd.read_csv('./data/small_movies_W.csv', header=None)\n",
    "w_data = np.array(w_data)\n",
    "\n",
    "# b (443, 1): bias parameters for 443 users\n",
    "b_data = pd.read_csv('./data/small_movies_b.csv', header=None)\n",
    "b_data = np.array(b_data.T)\n",
    "b_data = b_data.reshape(len(b_data), )\n",
    "\n",
    "# x (4778. 10): 4778 movies with 10 features\n",
    "x_data = pd.read_csv('./data/small_movies_X.csv', header=None)\n",
    "x_data = np.array(x_data)\n",
    "\n",
    "# y (4778, 443): 4778 movies rated by 443 users\n",
    "y_data = pd.read_csv('./data/small_movies_Y.csv', header=None)\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "# r (4778, 443): wheter a movie has been rated\n",
    "r_data = pd.read_csv('./data/small_movies_R.csv', header=None)\n",
    "r_data = np.array(r_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w (users)\t (443, 10)\n",
      "b (users)\t (443,)\n",
      "x (movies)\t (4778, 10)\n",
      "y (ratings)\t (4778, 443)\n",
      "r (rated)\t (4778, 443)\n"
     ]
    }
   ],
   "source": [
    "print(f'w (users)\\t {w_data.shape}')\n",
    "print(f'b (users)\\t {b_data.shape}')\n",
    "print(f'x (movies)\\t {x_data.shape}')\n",
    "print(f'y (ratings)\\t {y_data.shape}')\n",
    "print(f'r (rated)\\t {r_data.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is given by \n",
    "$$J = \\frac{1}{2} \\sum_{(i,j): r(i,j)=1}(w^jx^i + b^j - y^{i,j})^2 + \\frac{\\lambda}{2}\n",
    "\\sum_{j=1}^{n_u}\\sum_{k=1}^{n}(\\mathbf{w}^{j}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=1}^{n_m}\\sum_{k=1}^{n}(\\mathbf{x}_k^{i})^2$$ \n",
    "\n",
    "- $n_u$: number of users\n",
    "- $n_m$: number of movies\n",
    "- $n$: number of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(x, w, b, y, r, lambda_):\n",
    "    nm, nu = y.shape\n",
    "\n",
    "    J = 0\n",
    "    for i in range(nm):\n",
    "        for j in range(nu):\n",
    "            sq_dif = r[i, j] * (w[j] @ x[i] + b[j] - y[i, j]) ** 2\n",
    "            J += sq_dif\n",
    "    J += lambda_ * (np.sum(np.square(w)) + np.sum(np.square(x)))\n",
    "    J /= 2\n",
    "\n",
    "    return J\n",
    "\n",
    "# vectorized implementation\n",
    "def cost_v(x, w, b, y, r, lambda_):\n",
    "    j = (tf.linalg.matmul(x, tf.transpose(w)) + b - y)*r\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(x**2) + tf.reduce_sum(w**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cost_fn(cost_fn):\n",
    "    nu = 4\n",
    "    nm = 5 \n",
    "    n = 3\n",
    "\n",
    "    x = np.ones((nm, n))\n",
    "    w = np.ones((nu, n))\n",
    "    b = np.zeros((nu, ))\n",
    "    y = np.zeros((nm, nu))\n",
    "    r = np.zeros((nm, nu))\n",
    "\n",
    "    J = cost_fn(x, w, b, y, r, 2)\n",
    "    assert np.isclose(J , 27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cost_fn(cost)\n",
    "test_cost_fn(cost_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for  Shrek (2001)\n",
      "Rated 5.0 for  Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Rated 2.0 for  Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "Rated 5.0 for  Harry Potter and the Chamber of Secrets (2002)\n",
      "Rated 5.0 for  Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Rated 5.0 for  Lord of the Rings: The Return of the King, The (2003)\n",
      "Rated 3.0 for  Eternal Sunshine of the Spotless Mind (2004)\n",
      "Rated 5.0 for  Incredibles, The (2004)\n",
      "Rated 2.0 for  Persuasion (2007)\n",
      "Rated 5.0 for  Toy Story 3 (2010)\n",
      "Rated 3.0 for  Inception (2010)\n",
      "Rated 1.0 for  Louis Theroux: Law & Disorder (2008)\n",
      "Rated 1.0 for  Nothing to Declare (Rien à déclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "def load_movies():\n",
    "    \"\"\" returns df with and index of movies in the order they are in in the Y matrix \"\"\"\n",
    "    df = pd.read_csv('./data/small_movie_list.csv', header=0, index_col=0,  delimiter=',', quotechar='\"')\n",
    "    mlist = df[\"title\"].to_list()\n",
    "    return(mlist, df)\n",
    "\n",
    "\n",
    "movieList, movieList_df = load_movies()\n",
    "\n",
    "my_ratings = np.zeros(len(movieList))          #  Initialize my ratings\n",
    "\n",
    "# Check the file small_movie_list.csv for id of each movie in our dataset\n",
    "# For example, Toy Story 3 (2010) has ID 2700, so to rate it \"5\", you can set\n",
    "my_ratings[2700] = 5 \n",
    "\n",
    "#Or suppose you did not enjoy Persuasion (2007), you can set\n",
    "my_ratings[2609] = 2;\n",
    "\n",
    "# We have selected a few movies we liked / did not like and the ratings we\n",
    "# gave are as follows:\n",
    "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
    "my_ratings[246]  = 5   # Shrek (2001)\n",
    "my_ratings[2716] = 3   # Inception\n",
    "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
    "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'Amélie Poulain, Le)\n",
    "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
    "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
    "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
    "my_ratings[2937] = 1   # Nothing to Declare (Rien à déclarer)\n",
    "my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,\"title\"]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeRatings(Y, R):\n",
    "    Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R)\n",
    "    return(Ynorm, Ymean)\n",
    "\n",
    "# Reload ratings and add new ratings\n",
    "Y    = np.c_[my_ratings, y_data]\n",
    "R    = np.c_[(my_ratings != 0).astype(int), r_data]\n",
    "\n",
    "# Normalize the Dataset\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize learning parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm, nu = Ynorm.shape\n",
    "n = 100\n",
    "\n",
    "w = tf.Variable(tf.random.normal((nu, n), dtype=tf.float64), name='w')\n",
    "b = tf.Variable(tf.random.normal((nu, ), dtype=tf.float64), name='b')\n",
    "x = tf.Variable(tf.random.normal((nm, n), dtype=tf.float64), name='x')\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run gradient descent\n",
    "Use `GradientTape` to help calculate derivatives of the cost function and `Adam` optimizer to apply gradients to existing values of $x$, $w$, and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2262367.1\n",
      "14603.8\n",
      "2657.1\n",
      "1962.8\n",
      "1852.0\n",
      "1814.0\n",
      "1795.4\n",
      "1784.7\n",
      "1778.2\n",
      "1773.8\n"
     ]
    }
   ],
   "source": [
    "n_iter = 500\n",
    "lambda_ = 1\n",
    "\n",
    "for i in range(n_iter):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost_value = cost_v(x, w, b, Ynorm, R, lambda_)\n",
    "\n",
    "    gradients = tape.gradient(cost_value, [x, w, b])\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, [x, w, b]))\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(f'{cost_value:0.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 4.73 for movie Colourful (Karafuru) (2010)\n",
      "Predicting rating 4.58 for movie Battle Royale 2: Requiem (Batoru rowaiaru II: Chinkonka) (2003)\n",
      "Predicting rating 4.58 for movie Eichmann (2007)\n",
      "Predicting rating 4.58 for movie Into the Abyss (2011)\n",
      "Predicting rating 4.58 for movie One I Love, The (2014)\n",
      "Predicting rating 4.58 for movie Laggies (2014)\n",
      "Predicting rating 4.58 for movie Delirium (2014)\n",
      "Predicting rating 4.56 for movie 'Salem's Lot (2004)\n",
      "Predicting rating 4.56 for movie Particle Fever (2013)\n",
      "Predicting rating 4.55 for movie Kung Fu Panda: Secrets of the Masters (2011)\n",
      "Predicting rating 4.54 for movie Seve (2014)\n",
      "Predicting rating 4.53 for movie Battle For Sevastopol (2015)\n",
      "Predicting rating 4.53 for movie Che: Part One (2008)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5, Predicted 5 for Shrek (2001)\n",
      "Original 5, Predicted 5 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Original 2, Predicted 2 for Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "Original 5, Predicted 5 for Harry Potter and the Chamber of Secrets (2002)\n",
      "Original 5, Predicted 5 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Original 5, Predicted 5 for Lord of the Rings: The Return of the King, The (2003)\n",
      "Original 3, Predicted 3 for Eternal Sunshine of the Spotless Mind (2004)\n",
      "Original 5, Predicted 5 for Incredibles, The (2004)\n",
      "Original 2, Predicted 2 for Persuasion (2007)\n",
      "Original 5, Predicted 5 for Toy Story 3 (2010)\n",
      "Original 3, Predicted 3 for Inception (2010)\n",
      "Original 1, Predicted 1 for Louis Theroux: Law & Disorder (2008)\n",
      "Original 1, Predicted 1 for Nothing to Declare (Rien à déclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction using trained weights and biases\n",
    "p = np.matmul(x.numpy(), np.transpose(w.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "sorted_idx = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "# First 20 movies\n",
    "for i in range(20):\n",
    "    movie_idx = sorted_idx[i]\n",
    "    if movie_idx not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[movie_idx]:0.2f} for movie {movieList[movie_idx]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
